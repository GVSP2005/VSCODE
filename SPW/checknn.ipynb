{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\saipr\\Downloads\\creditcard.csv\\creditcard.csv\")\n",
    "df.dropna(inplace=True)\n",
    "x=df[df.columns[:-1]]\n",
    "y=df[df.columns[-1]]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "y_test.value_counts()\n",
    "smote=SMOTE(random_state=42)\n",
    "x_train,y_train=smote.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.tensor(np.array(x_train),dtype=torch.float32)\n",
    "x_test=torch.tensor(np.array(x_test),dtype=torch.float32)\n",
    "y_test=torch.tensor(np.array(y_test),dtype=torch.float32)\n",
    "y_train=torch.tensor(np.array(y_train),dtype=torch.float32)\n",
    "train_data=TensorDataset(x_train,y_train)\n",
    "test_data=TensorDataset(x_test,y_test)\n",
    "train_loader=DataLoader(train_data,batch_size=64,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=64,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNLog(nn.Module):\n",
    "    def __init__(self,input_size=30,output_size=1):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(input_size,output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NNLog()\n",
    "criterion=nn.BCELoss()\n",
    "optimiser=optim.Adam(model.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 1:50.0\n",
      "loss at epoch 2:59.25925827026367\n",
      "loss at epoch 3:53.703704833984375\n",
      "loss at epoch 4:50.0\n",
      "loss at epoch 5:53.703704833984375\n",
      "loss at epoch 6:46.296295166015625\n",
      "loss at epoch 7:59.25925827026367\n",
      "loss at epoch 8:57.407405853271484\n",
      "loss at epoch 9:48.14814758300781\n",
      "loss at epoch 10:51.85185241699219\n",
      "loss at epoch 11:40.74074172973633\n",
      "loss at epoch 12:51.85185241699219\n",
      "loss at epoch 13:61.11111068725586\n",
      "loss at epoch 14:51.85185241699219\n",
      "loss at epoch 15:51.85185241699219\n",
      "loss at epoch 16:46.296295166015625\n",
      "loss at epoch 17:51.85185241699219\n",
      "loss at epoch 18:48.14814758300781\n",
      "loss at epoch 19:51.85185241699219\n",
      "loss at epoch 20:55.55555725097656\n",
      "loss at epoch 21:48.14814758300781\n",
      "loss at epoch 22:48.14814758300781\n",
      "loss at epoch 23:44.44444274902344\n",
      "loss at epoch 24:42.592594146728516\n",
      "loss at epoch 25:48.14814758300781\n",
      "loss at epoch 26:57.407405853271484\n",
      "loss at epoch 27:55.55555725097656\n",
      "loss at epoch 28:37.03703689575195\n",
      "loss at epoch 29:33.33333206176758\n",
      "loss at epoch 30:51.85185241699219\n",
      "loss at epoch 31:61.11111068725586\n",
      "loss at epoch 32:57.407405853271484\n",
      "loss at epoch 33:57.407405853271484\n",
      "loss at epoch 34:48.14814758300781\n",
      "loss at epoch 35:37.03703689575195\n",
      "loss at epoch 36:46.296295166015625\n",
      "loss at epoch 37:50.0\n",
      "loss at epoch 38:59.25925827026367\n",
      "loss at epoch 39:53.703704833984375\n",
      "loss at epoch 40:64.81481170654297\n",
      "loss at epoch 41:57.407405853271484\n",
      "loss at epoch 42:55.55555725097656\n",
      "loss at epoch 43:57.407405853271484\n",
      "loss at epoch 44:46.296295166015625\n",
      "loss at epoch 45:53.703704833984375\n",
      "loss at epoch 46:53.703704833984375\n",
      "loss at epoch 47:51.85185241699219\n",
      "loss at epoch 48:53.703704833984375\n",
      "loss at epoch 49:46.296295166015625\n",
      "loss at epoch 50:50.0\n",
      "loss at epoch 51:46.296295166015625\n",
      "loss at epoch 52:50.0\n",
      "loss at epoch 53:53.703704833984375\n",
      "loss at epoch 54:62.96296310424805\n",
      "loss at epoch 55:44.44444274902344\n",
      "loss at epoch 56:42.592594146728516\n",
      "loss at epoch 57:53.703704833984375\n",
      "loss at epoch 58:40.74074172973633\n",
      "loss at epoch 59:62.96296310424805\n",
      "loss at epoch 60:62.96296310424805\n",
      "loss at epoch 61:53.703704833984375\n",
      "loss at epoch 62:46.296295166015625\n",
      "loss at epoch 63:57.407405853271484\n",
      "loss at epoch 64:48.14814758300781\n",
      "loss at epoch 65:61.11111068725586\n",
      "loss at epoch 66:37.03703689575195\n",
      "loss at epoch 67:51.85185241699219\n",
      "loss at epoch 68:33.33333206176758\n",
      "loss at epoch 69:48.14814758300781\n",
      "loss at epoch 70:42.592594146728516\n",
      "loss at epoch 71:48.14814758300781\n",
      "loss at epoch 72:57.407405853271484\n",
      "loss at epoch 73:51.85185241699219\n",
      "loss at epoch 74:44.44444274902344\n",
      "loss at epoch 75:42.592594146728516\n",
      "loss at epoch 76:44.44444274902344\n",
      "loss at epoch 77:53.703704833984375\n",
      "loss at epoch 78:59.25925827026367\n",
      "loss at epoch 79:57.407405853271484\n",
      "loss at epoch 80:57.407405853271484\n",
      "loss at epoch 81:51.85185241699219\n",
      "loss at epoch 82:46.296295166015625\n",
      "loss at epoch 83:62.96296310424805\n",
      "loss at epoch 84:48.14814758300781\n",
      "loss at epoch 85:44.44444274902344\n",
      "loss at epoch 86:44.44444274902344\n",
      "loss at epoch 87:51.85185241699219\n",
      "loss at epoch 88:55.55555725097656\n",
      "loss at epoch 89:40.74074172973633\n",
      "loss at epoch 90:42.592594146728516\n",
      "loss at epoch 91:66.66666412353516\n",
      "loss at epoch 92:57.407405853271484\n",
      "loss at epoch 93:35.185184478759766\n",
      "loss at epoch 94:40.74074172973633\n",
      "loss at epoch 95:57.407405853271484\n",
      "loss at epoch 96:50.0\n",
      "loss at epoch 97:51.85185241699219\n",
      "loss at epoch 98:51.85185241699219\n",
      "loss at epoch 99:40.74074172973633\n",
      "loss at epoch 100:38.88888931274414\n",
      "loss at epoch 101:40.74074172973633\n",
      "loss at epoch 102:33.33333206176758\n",
      "loss at epoch 103:40.74074172973633\n",
      "loss at epoch 104:53.703704833984375\n",
      "loss at epoch 105:48.14814758300781\n",
      "loss at epoch 106:51.85185241699219\n",
      "loss at epoch 107:50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:316\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:173\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    170\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\collate.py:213\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    211\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    212\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for input,output in train_loader:\n",
    "        pred_output=model(input)\n",
    "        loss=criterion(pred_output.squeeze(),output)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(f\"loss at epoch {epoch+1}:{loss}\")\n",
    "    if loss <10e-20:\n",
    "        print(epoch)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,loader):\n",
    "    model.eval()\n",
    "    y_true,y_pred=[],[]\n",
    "    with torch.no_grad():\n",
    "        for input,output in loader:\n",
    "            pred_output=model(input)\n",
    "            pred_output=pred_output.squeeze()\n",
    "            pred_output_np=pred_output.detach().cpu().numpy().flatten()\n",
    "            output_np=output.detach().cpu().numpy().flatten()\n",
    "            y_true.extend(output_np.tolist())\n",
    "            y_pred.extend(pred_output_np.tolist())\n",
    "    model.train()\n",
    "    y_pred=list(1 if k>=0.5 else 0 for k in y_pred )\n",
    "    t1=sum(1 for j in y_true if j==1)\n",
    "    t0=len(y_true)-t1\n",
    "    c1=sum(1 for j,k in zip(y_true,y_pred) if j==1 and k==1)\n",
    "    c0=sum(1 for j,k in zip(y_true,y_pred) if j==0 and k==0)\n",
    "    print(\"precision_score\")\n",
    "    print(f\"class1:{c1}/{t1},class0:{c0}/{t0}\")\n",
    "    print(\"classification_report:\")\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print('confusion matrix:')\n",
    "    print(confusion_matrix(y_true,y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score\n",
      "class1:0/394,class0:227451/227451\n",
      "classification_report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saipr\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saipr\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    227451\n",
      "         1.0       0.00      0.00      0.00       394\n",
      "\n",
      "    accuracy                           1.00    227845\n",
      "   macro avg       0.50      0.50      0.50    227845\n",
      "weighted avg       1.00      1.00      1.00    227845\n",
      "\n",
      "confusion matrix:\n",
      "[[227451      0]\n",
      " [   394      0]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model,train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(model,test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
